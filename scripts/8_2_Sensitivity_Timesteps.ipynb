{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b454d78-c2b0-4256-b1ee-33ad92062cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STATIC PPO: Per-Iteration Training Log (head) ===\n",
      " Time-steps  Ep. Len  Ep. Reward  Policy Grad. Loss  Value Loss  Entropy Loss  KL Divergence  Total Loss\n",
      "       2048      NaN         NaN                NaN         NaN           NaN            NaN         NaN\n",
      "       4096   2281.0     -4055.0          -0.040131  771.707002     -0.683103       0.019554  770.983768\n",
      "       6144   2281.0     -3497.0          -0.046810  406.110355     -0.620498       0.023908  405.443047\n",
      "       8192   2281.0     -2829.0          -0.041010  110.765680     -0.476688       0.049052  110.247982\n",
      "      10240   2281.0     -1973.0          -0.030479   53.573654     -0.282799       0.108313   53.260376\n",
      "\n",
      "=== SEQUENTIAL PPO: Per-Iteration Training Log (head) ===\n",
      " Time-steps  Ep. Len  Ep. Reward  Policy Grad. Loss  Value Loss  Entropy Loss  KL Divergence  Total Loss\n",
      "       2048     1.74     -1.2534                NaN         NaN           NaN            NaN         NaN\n",
      "       4096     1.51     -0.7651          -0.124109    6.502743     -0.665316       0.029434    5.713318\n",
      "       6144     1.39     -0.1759          -0.141333    5.414640     -0.565204       0.038563    4.708103\n",
      "       8192     1.61      1.0559          -0.125157    4.327869     -0.353052       0.092691    3.849660\n",
      "      10240     1.45      1.7755          -0.060573    2.946760     -0.114984       0.212365    2.771202\n"
     ]
    }
   ],
   "source": [
    "import os, time, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(42); np.random.seed(42)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "TOTAL_STEPS_PPO = 100_000\n",
    "BATCH_SIZE = 64\n",
    "N_STEPS = 2048\n",
    "LEARNING_RATE = 3e-4\n",
    "ENT_COEF = 0.0\n",
    "N_EPOCHS = 10\n",
    "\n",
    "from pathlib import Path\n",
    "candidates = [\n",
    "    Path(\"Data/Hybrid_Augmented_TSAFE_Features.xlsx\"),\n",
    "    Path(\"../Data/Hybrid_Augmented_TSAFE_Features.xlsx\"),\n",
    "    Path(\"../data/Hybrid_Augmented_TSAFE_Features.xlsx\"),\n",
    "]\n",
    "for p in candidates:\n",
    "    if p.exists():\n",
    "        file_path = str(p)\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find Excel. Tried: {candidates}. CWD={Path.cwd()}\"\n",
    "    )\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "if 'Plant_Destination' not in df.columns:\n",
    "    if {'Plant Code', 'Destination Port'}.issubset(df.columns):\n",
    "        df['Plant_Destination'] = df['Plant Code'].astype(str) + ' | ' + df['Destination Port'].astype(str)\n",
    "    else:\n",
    "        raise ValueError(\"Cannot create 'Plant_Destination': missing 'Plant Code' or 'Destination Port'.\")\n",
    "\n",
    "cat_features = ['Origin Port','Carrier','Plant Code','Destination Port','Plant_Destination']\n",
    "num_features = [\n",
    "    'Unit quantity','Weight','TPT',\n",
    "    'TPT_per_Unit','LeadTime_Deviation','Weight_per_Unit','log_UnitQty',\n",
    "    'carrier_origin_risk','route_cum_late_rate','route_bb_mean','carrier_bb_mean',\n",
    "    'route_orders_last7d','route_roll10_Weight_q90',\n",
    "    'congestion_trend','Weight_vsCarrierMean','seq_pos_norm'\n",
    "]\n",
    "\n",
    "requested = [c for c in (cat_features + num_features) if c in df.columns]\n",
    "missing = sorted(set(cat_features + num_features) - set(requested))\n",
    "if missing:\n",
    "    print(f\"[WARN] Skipping missing columns: {missing}\")\n",
    "\n",
    "X_raw = pd.get_dummies(df[requested], drop_first=False)\n",
    "y = (df['Ship Late Day count'] > 0).astype(int)\n",
    "\n",
    "X_raw = X_raw.replace([np.inf,-np.inf], np.nan).fillna(X_raw.median(numeric_only=True))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_raw, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "def create_model(model_type, input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim, 1)))\n",
    "    if model_type == 'CNN':\n",
    "        model.add(Conv1D(64, 2, activation='relu')); model.add(Flatten())\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(LSTM(64, activation='tanh'))\n",
    "    elif model_type == 'Bi-LSTM':\n",
    "        model.add(Bidirectional(LSTM(64, activation='tanh')))\n",
    "    elif model_type == 'Stacked LSTM':\n",
    "        model.add(LSTM(64, activation='tanh', return_sequences=True))\n",
    "        model.add(LSTM(32, activation='tanh'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3, clipnorm=1.0), loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "xgb = GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42, eval_metric=\"logloss\", verbosity=0),\n",
    "    param_grid={'n_estimators':[100],'max_depth':[3,5],'learning_rate':[0.1,0.05],'subsample':[0.8]},\n",
    "    scoring='roc_auc', cv=3, n_jobs=-1\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_proba = xgb.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "X_train_dl = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "X_test_dl  = X_test_scaled.reshape(-1,  X_test_scaled.shape[1],  1)\n",
    "\n",
    "dl_models = ['CNN','LSTM','Bi-LSTM','Stacked LSTM']\n",
    "dl_outputs = {}\n",
    "for m in dl_models:\n",
    "    mdl = create_model(m, X_train_dl.shape[1])\n",
    "    mdl.fit(X_train_dl, y_train_res, epochs=10, batch_size=256, verbose=0)\n",
    "    dl_outputs[m] = mdl.predict(X_test_dl, verbose=0).reshape(-1)\n",
    "\n",
    "ppo_input_static = np.vstack([xgb_proba, dl_outputs['CNN'], dl_outputs['LSTM'],\n",
    "                              dl_outputs['Bi-LSTM'], dl_outputs['Stacked LSTM']]).T.astype(np.float32)\n",
    "ppo_input_static = MinMaxScaler().fit_transform(ppo_input_static).astype(np.float32)\n",
    "ppo_labels_static = y_test.values.astype(int)\n",
    "\n",
    "class PPOHybridEnv(gym.Env):\n",
    "    \"\"\"Static classification PPO. One episode = pass through test rows once.\"\"\"\n",
    "    metadata = {\"render_modes\": []}\n",
    "    def __init__(self, inputs, labels, pos_reward=1.0, neg_reward=-5.0):\n",
    "        super().__init__()\n",
    "        self.inputs = inputs; self.labels = labels.astype(int)\n",
    "        self.n = len(labels); self.pos_reward = pos_reward; self.neg_reward = neg_reward\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(inputs.shape[1],), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(2); self.idx = 0\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed); self.idx = 0\n",
    "        return self.inputs[self.idx], {}\n",
    "    def step(self, action):\n",
    "        y = self.labels[self.idx]\n",
    "        reward = self.pos_reward if action == y else self.neg_reward\n",
    "        self.idx += 1\n",
    "        terminated = self.idx >= self.n\n",
    "        obs = np.zeros(self.inputs.shape[1], dtype=np.float32) if terminated else self.inputs[self.idx]\n",
    "        return obs, float(reward), terminated, False, {}\n",
    "\n",
    "test_idx = X_test.index\n",
    "test_frame = df.loc[test_idx, ['Order Date','Origin Port','Destination Port','Carrier']].copy()\n",
    "test_frame['Order Date'] = pd.to_datetime(test_frame['Order Date'])\n",
    "test_frame['y'] = y_test.values.astype(int)\n",
    "test_frame['xgb'] = xgb_proba\n",
    "for m in dl_models: test_frame[m] = dl_outputs[m]\n",
    "test_frame['route_key'] = (test_frame['Origin Port'].astype(str) + ' | ' +\n",
    "                           test_frame['Destination Port'].astype(str) + ' | ' +\n",
    "                           test_frame['Carrier'].astype(str))\n",
    "test_frame = test_frame.sort_values('Order Date').reset_index(drop=True)\n",
    "\n",
    "base_inputs = test_frame[['xgb','CNN','LSTM','Bi-LSTM','Stacked LSTM']].values.astype(np.float32)\n",
    "base_inputs = MinMaxScaler().fit_transform(base_inputs).astype(np.float32)\n",
    "labels_sorted = test_frame['y'].values.astype(int)\n",
    "route_sorted  = test_frame['route_key'].values\n",
    "\n",
    "episodes = []\n",
    "start = 0\n",
    "for i in range(1, len(test_frame)+1):\n",
    "    if i == len(test_frame) or route_sorted[i] != route_sorted[i-1]:\n",
    "        episodes.append(slice(start, i)); start = i\n",
    "\n",
    "class SequentialPPOEnv(gym.Env):\n",
    "    \"\"\"Sequential PPO with temporal context and cost-sensitive rewards.\"\"\"\n",
    "    metadata = {\"render_modes\": []}\n",
    "    def __init__(self, base_inputs, labels, episodes, K=5):\n",
    "        super().__init__()\n",
    "        self.base_inputs = base_inputs; self.labels = labels.astype(int); self.episodes = episodes; self.K = K\n",
    "        self.obs_dim = 5 + 2 + K + 2\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.obs_dim,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self._ep_idx = -1; self._indices = None; self._t = None\n",
    "        self._last_actions = None; self._cum_fp = None; self._cum_fn = None; self._prev_fn_rate = 0.0\n",
    "    def _time_features(self, t, T):\n",
    "        pos = (t / max(T-1, 1)); return np.array([np.sin(2*np.pi*pos), np.cos(2*np.pi*pos)], dtype=np.float32)\n",
    "    def _obs(self):\n",
    "        T = len(self._indices); cur_idx = self._indices[self._t]\n",
    "        x = self.base_inputs[cur_idx]; time_feat = self._time_features(self._t, T); lastK = self._last_actions.copy()\n",
    "        obs = np.concatenate([x, time_feat, lastK, np.array([self._cum_fp, self._cum_fn], dtype=np.float32)], axis=0)\n",
    "        return obs.astype(np.float32)\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self._ep_idx = (self._ep_idx + 1) % len(self.episodes)\n",
    "        sl = self.episodes[self._ep_idx]; self._indices = np.arange(sl.start, sl.stop, dtype=int); self._t = 0\n",
    "        self._last_actions = np.zeros(self.K, dtype=np.float32); self._cum_fp = 0.0; self._cum_fn = 0.0\n",
    "        self._prev_fn_rate = 0.0; return self._obs(), {}\n",
    "    def step(self, action):\n",
    "        cur_i = self._indices[self._t]; y = self.labels[cur_i]\n",
    "        if action == y: reward = 2.0 if y == 1 else 1.0\n",
    "        else:\n",
    "            if y == 1 and action == 0: reward = -5.0; self._cum_fn += 1.0\n",
    "            else:                      reward = -2.0; self._cum_fp += 1.0\n",
    "        reward -= 0.01\n",
    "        steps_so_far = float(self._t + 1); fn_rate = self._cum_fn / steps_so_far\n",
    "        if fn_rate < self._prev_fn_rate: reward += 0.2\n",
    "        self._prev_fn_rate = fn_rate\n",
    "        self._last_actions = np.roll(self._last_actions, -1); self._last_actions[-1] = float(action)\n",
    "        self._t += 1; terminated = self._t >= len(self._indices)\n",
    "        obs = np.zeros(self.obs_dim, dtype=np.float32) if terminated else self._obs()\n",
    "        return obs, float(reward), terminated, False, {}\n",
    "\n",
    "def train_with_csv_logger(env_fn, log_root, total_steps=TOTAL_STEPS_PPO):\n",
    "    \"\"\"\n",
    "    Trains PPO, logging per-iteration metrics to CSV via SB3 logger,\n",
    "    then returns the loaded progress.csv as a DataFrame.\n",
    "    \"\"\"\n",
    "    os.makedirs(log_root, exist_ok=True)\n",
    "    env = make_vec_env(env_fn, n_envs=1, monitor_dir=os.path.join(log_root, \"monitor\"))\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\", env, verbose=0, seed=42,\n",
    "        n_steps=N_STEPS, batch_size=BATCH_SIZE, learning_rate=LEARNING_RATE,\n",
    "        ent_coef=ENT_COEF, n_epochs=N_EPOCHS\n",
    "    )\n",
    "   \n",
    "    new_logger = configure(log_root, [\"csv\"])\n",
    "    model.set_logger(new_logger)\n",
    "\n",
    "    model.learn(total_timesteps=total_steps)\n",
    "\n",
    "   \n",
    "    csv_path = os.path.join(log_root, \"progress.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"Expected {csv_path} not found. Check logger configuration.\")\n",
    "    df_prog = pd.read_csv(csv_path)\n",
    "    return model, env, df_prog, csv_path\n",
    "\n",
    "def extract_table_from_progress(df_prog):\n",
    "    \"\"\"\n",
    "    Map SB3 columns to the exact table the user requested.\n",
    "    Missing columns are filled with NaN (e.g., early iters without finished episodes).\n",
    "    \"\"\"\n",
    "   \n",
    "    cols = {\n",
    "        \"time/total_timesteps\": \"Time-steps\",\n",
    "        \"rollout/ep_len_mean\":  \"Ep. Len\",\n",
    "        \"rollout/ep_rew_mean\":  \"Ep. Reward\",\n",
    "        \"train/policy_gradient_loss\": \"Policy Grad. Loss\",\n",
    "        \"train/value_loss\":           \"Value Loss\",\n",
    "        \"train/entropy_loss\":         \"Entropy Loss\",\n",
    "        \"train/approx_kl\":            \"KL Divergence\",\n",
    "    }\n",
    "    out = pd.DataFrame()\n",
    "    for k, v in cols.items():\n",
    "        out[v] = df_prog[k] if k in df_prog.columns else np.nan\n",
    "   \n",
    "    out[\"Total Loss\"] = (\n",
    "        out[\"Policy Grad. Loss\"].astype(float) +\n",
    "        out[\"Value Loss\"].astype(float) +\n",
    "        out[\"Entropy Loss\"].astype(float)\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "static_log_root = \"./logs_static_ppo\"\n",
    "env_fn_static = lambda: PPOHybridEnv(ppo_input_static, ppo_labels_static)\n",
    "model_static, env_static, df_prog_static, path_csv_static = train_with_csv_logger(env_fn_static, static_log_root)\n",
    "\n",
    "table_static = extract_table_from_progress(df_prog_static)\n",
    "table_static.to_csv(\"ppo_training_log_static.csv\", index=False)\n",
    "print(\"\\n=== STATIC PPO: Per-Iteration Training Log (head) ===\")\n",
    "print(table_static.head().to_string(index=False))\n",
    "\n",
    "\n",
    "seq_log_root = \"./logs_sequential_ppo\"\n",
    "env_fn_seq = lambda: SequentialPPOEnv(base_inputs, labels_sorted, episodes, K=5)\n",
    "model_seq, env_seq, df_prog_seq, path_csv_seq = train_with_csv_logger(env_fn_seq, seq_log_root)\n",
    "\n",
    "table_seq = extract_table_from_progress(df_prog_seq)\n",
    "table_seq.to_csv(\"ppo_training_log_sequential.csv\", index=False)\n",
    "print(\"\\n=== SEQUENTIAL PPO: Per-Iteration Training Log (head) ===\")\n",
    "print(table_seq.head().to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda3)",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
