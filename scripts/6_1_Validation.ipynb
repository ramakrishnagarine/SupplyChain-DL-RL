{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45467586-6ce7-48af-87ea-0fd6b44cfe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results ===\n",
      "                  Model  Accuracy  Precision   Recall       F1  Time (s)\n",
      "PPO (Sequential Hybrid)  0.567460   0.754551 0.567460 0.410870     13.85\n",
      "                XGBoost  0.555556   0.545849 0.555556 0.546485      0.02\n",
      "                Bi-LSTM  0.440476   0.478741 0.440476 0.383044      1.46\n",
      "                   LSTM  0.424603   0.449870 0.424603 0.388866      0.94\n",
      "           Stacked LSTM  0.424603   0.373774 0.424603 0.271102      1.59\n",
      "                    CNN  0.408730   0.426057 0.408730 0.366644      0.55\n",
      "Saved: cm_cnn_300dpi.png\n",
      "Saved: cm_ppo_300dpi.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Simple SP500 Validation (Restricted Features)\n",
    "# X = ['Close','High','Low','Volume']; y = Direction (next-day up=1 else 0)\n",
    "# Models: XGBoost + CNN/LSTM/Bi-LSTM/Stacked LSTM + Sequential PPO\n",
    "# Metrics: Accuracy, Precision, Recall, F1\n",
    "# SMOTE on training only; PPO steps=50k; Reward (+1 / -5)\n",
    "# Saves CNN & PPO confusion matrices at 300 DPI\n",
    "# ============================================\n",
    "\n",
    "import warnings, time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "FILE_PATH = \"/Users/dhadel/Downloads/Validation_SP500_2017_2022.xlsx\"   # change if local\n",
    "TEST_SIZE = 0.20\n",
    "EPOCHS = 50\n",
    "RANDOM_STATE = 42\n",
    "PPO_STEPS = 50_000\n",
    "POS_REWARD, NEG_REWARD = 1, -5\n",
    "\n",
    "# -----------------------\n",
    "# Load & minimal prep\n",
    "# -----------------------\n",
    "df = pd.read_excel(FILE_PATH, engine=\"openpyxl\")\n",
    "\n",
    "# Keep only needed columns (must exist in file)\n",
    "df = df[['Date','Open','High','Low','Close','Volume']].copy()\n",
    "\n",
    "# Ensure numeric for features\n",
    "for c in ['Open','High','Low','Close','Volume']:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Target: next-day direction (1 if next Close > today Close)\n",
    "df['Direction'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
    "df = df.dropna(subset=['Close','High','Low','Volume','Direction']).copy()\n",
    "\n",
    "# Features & target\n",
    "X = df[['Close','High','Low','Volume']].copy()\n",
    "y = df['Direction'].astype(int)\n",
    "\n",
    "# Clean inf/nan\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# Split (mirror baseline style)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# SMOTE on training only\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale for DL\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def metrics_from_continuous(y_true, y_pred_cont):\n",
    "    yb = np.round(np.nan_to_num(y_pred_cont)).astype(int).clip(0,1)\n",
    "    return {\n",
    "        'Accuracy':  accuracy_score(y_true, yb),\n",
    "        'Precision': precision_score(y_true, yb, average='weighted', zero_division=1),\n",
    "        'Recall':    recall_score(y_true, yb, average='weighted', zero_division=1),\n",
    "        'F1':        f1_score(y_true, yb, average='weighted', zero_division=1)\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# -----------------------\n",
    "# XGBoost (regressor head like baseline)\n",
    "# -----------------------\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=120, max_depth=3, learning_rate=0.1, subsample=0.8,\n",
    "    n_jobs=-1, random_state=RANDOM_STATE\n",
    ")\n",
    "t0 = time.time()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_time = round(time.time() - t0, 2)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "res = metrics_from_continuous(y_test, xgb_pred); res.update({'Model':'XGBoost','Time (s)':xgb_time}); results.append(res)\n",
    "\n",
    "# -----------------------\n",
    "# DL models (tabular -> 1D)\n",
    "# -----------------------\n",
    "X_train_dl = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "X_test_dl  = X_test_scaled.reshape(-1,  X_test_scaled.shape[1], 1)\n",
    "\n",
    "def make_dl(kind, input_len):\n",
    "    m = Sequential([Input(shape=(input_len,1))])\n",
    "    if kind == 'CNN':\n",
    "        m.add(Conv1D(64, 2, activation='relu'))\n",
    "        m.add(Flatten())\n",
    "    elif kind == 'LSTM':\n",
    "        m.add(LSTM(50, activation='relu'))\n",
    "    elif kind == 'Bi-LSTM':\n",
    "        m.add(Bidirectional(LSTM(50, activation='relu')))\n",
    "    elif kind == 'Stacked LSTM':\n",
    "        m.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "        m.add(LSTM(50, activation='relu'))\n",
    "    m.add(Dense(1, activation='linear'))\n",
    "    m.compile(optimizer=Adam(1e-3, clipnorm=1.0), loss='mse')\n",
    "    return m\n",
    "\n",
    "dl_preds = {}\n",
    "for name in ['CNN','LSTM','Bi-LSTM','Stacked LSTM']:\n",
    "    mdl = make_dl(name, X_train_dl.shape[1])\n",
    "    t0 = time.time()\n",
    "    mdl.fit(X_train_dl, y_train_res, epochs=EPOCHS, verbose=0)\n",
    "    t_train = round(time.time() - t0, 2)\n",
    "    pred = mdl.predict(X_test_dl, verbose=0).ravel()\n",
    "    dl_preds[name] = pred\n",
    "    res = metrics_from_continuous(y_test, pred); res.update({'Model':name,'Time (s)':t_train}); results.append(res)\n",
    "\n",
    "# -----------------------\n",
    "# PPO Sequential Hybrid (meta over model outputs)\n",
    "# -----------------------\n",
    "stack = np.column_stack([\n",
    "    xgb_pred,\n",
    "    dl_preds['CNN'],\n",
    "    dl_preds['LSTM'],\n",
    "    dl_preds['Bi-LSTM'],\n",
    "    dl_preds['Stacked LSTM']\n",
    "]).astype(np.float32)\n",
    "\n",
    "stack = MinMaxScaler().fit_transform(stack).astype(np.float32)\n",
    "ppo_labels = y_test.values.astype(int)\n",
    "\n",
    "class PPOEnv(gym.Env):\n",
    "    def __init__(self, X, y, pos_reward=1, neg_reward=-5):\n",
    "        super().__init__()\n",
    "        self.X, self.y = X, y\n",
    "        self.n = len(y); self.i = 0\n",
    "        self.pos_reward, self.neg_reward = pos_reward, neg_reward\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(X.shape[1],), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.i = 0\n",
    "        return self.X[self.i], {}\n",
    "    def step(self, action):\n",
    "        r = self.pos_reward if action == self.y[self.i] else self.neg_reward\n",
    "        self.i += 1\n",
    "        done = self.i >= self.n\n",
    "        obs = self.X[self.i] if not done else np.zeros(self.X.shape[1], dtype=np.float32)\n",
    "        return obs, r, done, False, {}\n",
    "\n",
    "env = make_vec_env(lambda: PPOEnv(stack, ppo_labels, POS_REWARD, NEG_REWARD), n_envs=1)\n",
    "ppo = PPO(\"MlpPolicy\", env, verbose=0, seed=RANDOM_STATE)\n",
    "\n",
    "t0 = time.time()\n",
    "ppo.learn(total_timesteps=PPO_STEPS)\n",
    "ppo_time = round(time.time() - t0, 2)\n",
    "\n",
    "# Evaluate sequentially\n",
    "eval_env = PPOEnv(stack, ppo_labels, POS_REWARD, NEG_REWARD)\n",
    "obs, _ = eval_env.reset()\n",
    "ppo_preds = []\n",
    "done = False\n",
    "while not done:\n",
    "    act, _ = ppo.predict(obs, deterministic=True)\n",
    "    ppo_preds.append(int(act))\n",
    "    obs, _, done, _, _ = eval_env.step(int(act))\n",
    "\n",
    "# PPO metrics\n",
    "ppo_metrics = {\n",
    "    'Accuracy':  accuracy_score(ppo_labels, ppo_preds),\n",
    "    'Precision': precision_score(ppo_labels, ppo_preds, average='weighted', zero_division=1),\n",
    "    'Recall':    recall_score(ppo_labels, ppo_preds, average='weighted', zero_division=1),\n",
    "    'F1':        f1_score(ppo_labels, ppo_preds, average='weighted', zero_division=1)\n",
    "}\n",
    "ppo_metrics.update({'Model':'PPO (Sequential Hybrid)','Time (s)': ppo_time})\n",
    "results.append(ppo_metrics)\n",
    "\n",
    "# -----------------------\n",
    "# Report + Save CMs (300 DPI)\n",
    "# -----------------------\n",
    "out = pd.DataFrame(results)[['Model','Accuracy','Precision','Recall','F1','Time (s)']]\n",
    "print(\"\\n=== Results ===\")\n",
    "print(out.sort_values('Accuracy', ascending=False).to_string(index=False))\n",
    "\n",
    "# CNN CM\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, np.round(dl_preds['CNN']).astype(int).clip(0,1)),\n",
    "            annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"CNN Confusion Matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "plt.tight_layout(); plt.savefig(\"cm_cnn_300dpi.png\", dpi=300); plt.close()\n",
    "print(\"Saved: cm_cnn_300dpi.png\")\n",
    "\n",
    "# PPO CM\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(ppo_labels, ppo_preds),\n",
    "            annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"PPO Confusion Matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "plt.tight_layout(); plt.savefig(\"cm_ppo_300dpi.png\", dpi=300); plt.close()\n",
    "print(\"Saved: cm_ppo_300dpi.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6ad6202-dfea-41fe-86f3-5c34b306f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results (Improved) ===\n",
      "                  Model  Accuracy  Precision   Recall       F1  Time (s)\n",
      "                    CNN  0.564516   0.541432 0.564516 0.488886      0.88\n",
      "PPO (Sequential Hybrid)  0.564516   0.754162 0.564516 0.407383     12.73\n",
      "                Bi-LSTM  0.560484   0.517125 0.560484 0.437896      4.91\n",
      "                   LSTM  0.556452   0.519657 0.556452 0.466501      2.98\n",
      "                XGBoost  0.500000   0.500000 0.500000 0.500000      0.11\n",
      "           Stacked LSTM  0.495968   0.611082 0.495968 0.423582      5.92\n",
      "\n",
      "Saved metrics to: sp500_improved_results.csv\n",
      "Saved: cm_cnn_improved_300dpi.png\n",
      "Saved: cm_ppo_improved_300dpi.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Improved SP500 Validation (Better Features + Time-Series Split)\n",
    "# X base: ['Close','High','Low','Volume']  (+ engineered tech features)\n",
    "# y: Direction (next-day Close up=1 else 0)\n",
    "# Models: XGBoost + CNN/LSTM/Bi-LSTM/Stacked LSTM + Sequential PPO\n",
    "# Metrics: Accuracy, Precision, Recall, F1\n",
    "# SMOTE on training only; PPO steps=50k; Reward (+1 / -5)\n",
    "# Saves CNN & PPO confusion matrices at 300 DPI\n",
    "# ============================================================\n",
    "\n",
    "import warnings, time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "FILE_PATH = \"/Users/dhadel/Downloads/Validation_SP500_2017_2022.xlsx\"   # change if local\n",
    "RANDOM_STATE = 42\n",
    "TEST_FRACTION = 0.20          # last 20% by time for testing\n",
    "EPOCHS = 20                   # a bit more training for DL\n",
    "PPO_STEPS = 50_000\n",
    "POS_REWARD, NEG_REWARD = 1, -5\n",
    "RESULTS_CSV = \"sp500_improved_results.csv\"\n",
    "\n",
    "# Optional: band to ignore tiny moves (set to 0.0 to disable)\n",
    "# If you set e.g. 0.003 (0.3%), neutral days are dropped from training/testing.\n",
    "MIN_MOVE_BAND = 0.0\n",
    "\n",
    "# -----------------------\n",
    "# Load data\n",
    "# -----------------------\n",
    "df = pd.read_excel(FILE_PATH, engine=\"openpyxl\")\n",
    "\n",
    "# Keep only needed columns & ensure types\n",
    "df = df[['Date','Open','High','Low','Close','Volume']].copy()\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "for c in ['Open','High','Low','Close','Volume']:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "df = df.dropna(subset=['Date','Open','High','Low','Close','Volume']).sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# -----------------------\n",
    "# Target: next-day direction\n",
    "# -----------------------\n",
    "ret1 = df['Close'].pct_change().shift(-1)  # next-day return relative to today\n",
    "if MIN_MOVE_BAND > 0.0:\n",
    "    # Label only if move exceeds band; drop neutral days\n",
    "    df['Direction'] = np.where(ret1 > MIN_MOVE_BAND, 1, np.where(ret1 < -MIN_MOVE_BAND, 0, np.nan))\n",
    "    df = df.dropna(subset=['Direction']).copy()\n",
    "    df['Direction'] = df['Direction'].astype(int)\n",
    "else:\n",
    "    df['Direction'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
    "\n",
    "# Drop last row (no future label)\n",
    "df = df.iloc[:-1, :].copy()\n",
    "\n",
    "# -----------------------\n",
    "# Lightweight technical features (all causal: lags/rolling only)\n",
    "# -----------------------\n",
    "df['ret'] = df['Close'].pct_change()      # daily return (t - 1)\n",
    "# lagged returns\n",
    "for k in [1,2,3,5]:\n",
    "    df[f'lag_ret_{k}'] = df['ret'].shift(k)\n",
    "\n",
    "# moving averages & ratios\n",
    "for w in [5,10,20]:\n",
    "    df[f'ma_{w}'] = df['Close'].rolling(w, min_periods=w).mean()\n",
    "    df[f'ma_ratio_{w}'] = df['Close'] / (df[f'ma_{w}'] + 1e-12)\n",
    "\n",
    "# rolling volatility of returns\n",
    "for w in [5,10,20]:\n",
    "    df[f'vol_{w}'] = df['ret'].rolling(w, min_periods=w).std()\n",
    "\n",
    "# RSI(14)\n",
    "delta = df['Close'].diff()\n",
    "gain = delta.clip(lower=0).rolling(14, min_periods=14).mean()\n",
    "loss = (-delta.clip(upper=0)).rolling(14, min_periods=14).mean()\n",
    "rs = gain / (loss + 1e-12)\n",
    "df['rsi_14'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# MACD (12,26,9)\n",
    "ema12 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "ema26 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "macd = ema12 - ema26\n",
    "signal = macd.ewm(span=9, adjust=False).mean()\n",
    "df['macd'] = macd\n",
    "df['macd_signal'] = signal\n",
    "df['macd_hist'] = macd - signal\n",
    "\n",
    "# simple price ratios\n",
    "df['hl_range'] = (df['High'] - df['Low']) / (df['Close'] + 1e-12)\n",
    "df['co_ratio'] = df['Close'] / (df['Open'] + 1e-12)\n",
    "\n",
    "# Base features + engineered\n",
    "base_feats = ['Close','High','Low','Volume']\n",
    "eng_feats  = [c for c in [\n",
    "    'ret', 'lag_ret_1','lag_ret_2','lag_ret_3','lag_ret_5',\n",
    "    'ma_ratio_5','ma_ratio_10','ma_ratio_20',\n",
    "    'vol_5','vol_10','vol_20',\n",
    "    'rsi_14','macd','macd_signal','macd_hist',\n",
    "    'hl_range','co_ratio'\n",
    "] if c in df.columns]\n",
    "\n",
    "feature_cols = base_feats + eng_feats\n",
    "\n",
    "# Drop rows with NA introduced by rolling/lag features\n",
    "df = df.dropna(subset=feature_cols + ['Direction']).copy()\n",
    "\n",
    "X_all = df[feature_cols].replace([np.inf,-np.inf], np.nan).fillna(method='ffill').fillna(method='bfill')\n",
    "y_all = df['Direction'].astype(int).values\n",
    "dates = df['Date'].values\n",
    "\n",
    "# -----------------------\n",
    "# Time-series split (chronological 80/20)\n",
    "# -----------------------\n",
    "n = len(df)\n",
    "test_start = int(np.floor((1.0 - TEST_FRACTION) * n))\n",
    "X_train, X_test = X_all.iloc[:test_start], X_all.iloc[test_start:]\n",
    "y_train, y_test = y_all[:test_start], y_all[test_start:]\n",
    "dates_train, dates_test = dates[:test_start], dates[test_start:]\n",
    "\n",
    "# -----------------------\n",
    "# SMOTE on training only + scaling for DL\n",
    "# -----------------------\n",
    "sm = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def metrics_from_continuous(y_true, y_pred_cont):\n",
    "    yb = np.round(np.nan_to_num(y_pred_cont)).astype(int).clip(0,1)\n",
    "    return {\n",
    "        'Accuracy':  accuracy_score(y_true, yb),\n",
    "        'Precision': precision_score(y_true, yb, average='weighted', zero_division=1),\n",
    "        'Recall':    recall_score(y_true, yb, average='weighted', zero_division=1),\n",
    "        'F1':        f1_score(y_true, yb, average='weighted', zero_division=1)\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# -----------------------\n",
    "# 1) XGBoost (regressor head to mirror baseline behavior)\n",
    "# -----------------------\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=200, max_depth=4, learning_rate=0.05, subsample=0.8,\n",
    "    colsample_bytree=0.9, n_jobs=-1, random_state=RANDOM_STATE\n",
    ")\n",
    "t0 = time.time()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_time = round(time.time() - t0, 2)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "res = metrics_from_continuous(y_test, xgb_pred); res.update({'Model':'XGBoost','Time (s)':xgb_time}); results.append(res)\n",
    "\n",
    "# -----------------------\n",
    "# 2) DL models\n",
    "# -----------------------\n",
    "X_train_dl = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "X_test_dl  = X_test_scaled.reshape(-1,  X_test_scaled.shape[1], 1)\n",
    "\n",
    "def make_dl(kind, input_len):\n",
    "    m = Sequential([Input(shape=(input_len,1))])\n",
    "    if kind == 'CNN':\n",
    "        m.add(Conv1D(64, 3, activation='relu'))\n",
    "        m.add(Flatten())\n",
    "    elif kind == 'LSTM':\n",
    "        m.add(LSTM(64, activation='relu'))\n",
    "    elif kind == 'Bi-LSTM':\n",
    "        m.add(Bidirectional(LSTM(64, activation='relu')))\n",
    "    elif kind == 'Stacked LSTM':\n",
    "        m.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "        m.add(LSTM(64, activation='relu'))\n",
    "    m.add(Dense(1, activation='linear'))\n",
    "    m.compile(optimizer=Adam(1e-3, clipnorm=1.0), loss='mse')\n",
    "    return m\n",
    "\n",
    "dl_preds = {}\n",
    "for name in ['CNN','LSTM','Bi-LSTM','Stacked LSTM']:\n",
    "    mdl = make_dl(name, X_train_dl.shape[1])\n",
    "    t0 = time.time()\n",
    "    mdl.fit(X_train_dl, y_train_res, epochs=EPOCHS, verbose=0)\n",
    "    elapsed = round(time.time() - t0, 2)\n",
    "    pred = mdl.predict(X_test_dl, verbose=0).ravel()\n",
    "    dl_preds[name] = pred\n",
    "    res = metrics_from_continuous(y_test, pred); res.update({'Model':name,'Time (s)':elapsed}); results.append(res)\n",
    "\n",
    "# -----------------------\n",
    "# 3) PPO Sequential Hybrid (meta over model outputs)\n",
    "# -----------------------\n",
    "stack = np.column_stack([\n",
    "    xgb_pred,\n",
    "    dl_preds['CNN'],\n",
    "    dl_preds['LSTM'],\n",
    "    dl_preds['Bi-LSTM'],\n",
    "    dl_preds['Stacked LSTM']\n",
    "]).astype(np.float32)\n",
    "\n",
    "stack = MinMaxScaler().fit_transform(stack).astype(np.float32)\n",
    "ppo_labels = y_test.astype(int)\n",
    "\n",
    "class PPOEnv(gym.Env):\n",
    "    def __init__(self, X, y, pos_reward=1, neg_reward=-5):\n",
    "        super().__init__()\n",
    "        self.X, self.y = X, y\n",
    "        self.n = len(y); self.i = 0\n",
    "        self.pos_reward, self.neg_reward = pos_reward, neg_reward\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(X.shape[1],), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.i = 0\n",
    "        return self.X[self.i], {}\n",
    "    def step(self, action):\n",
    "        r = self.pos_reward if action == self.y[self.i] else self.neg_reward\n",
    "        self.i += 1\n",
    "        done = self.i >= self.n\n",
    "        obs = self.X[self.i] if not done else np.zeros(self.X.shape[1], dtype=np.float32)\n",
    "        return obs, r, done, False, {}\n",
    "\n",
    "env = make_vec_env(lambda: PPOEnv(stack, ppo_labels, POS_REWARD, NEG_REWARD), n_envs=1)\n",
    "ppo = PPO(\"MlpPolicy\", env, verbose=0, seed=RANDOM_STATE)\n",
    "\n",
    "t0 = time.time()\n",
    "ppo.learn(total_timesteps=PPO_STEPS)\n",
    "ppo_time = round(time.time() - t0, 2)\n",
    "\n",
    "# Evaluate sequentially\n",
    "eval_env = PPOEnv(stack, ppo_labels, POS_REWARD, NEG_REWARD)\n",
    "obs, _ = eval_env.reset()\n",
    "ppo_preds = []\n",
    "done = False\n",
    "while not done:\n",
    "    act, _ = ppo.predict(obs, deterministic=True)\n",
    "    ppo_preds.append(int(act))\n",
    "    obs, _, done, _, _ = eval_env.step(int(act))\n",
    "\n",
    "# PPO metrics\n",
    "ppo_metrics = {\n",
    "    'Accuracy':  accuracy_score(ppo_labels, ppo_preds),\n",
    "    'Precision': precision_score(ppo_labels, ppo_preds, average='weighted', zero_division=1),\n",
    "    'Recall':    recall_score(ppo_labels, ppo_preds, average='weighted', zero_division=1),\n",
    "    'F1':        f1_score(ppo_labels, ppo_preds, average='weighted', zero_division=1)\n",
    "}\n",
    "ppo_metrics.update({'Model':'PPO (Sequential Hybrid)','Time (s)': ppo_time})\n",
    "results.append(ppo_metrics)\n",
    "\n",
    "# -----------------------\n",
    "# Report + Save (300 DPI CMs)\n",
    "# -----------------------\n",
    "out = pd.DataFrame(results)[['Model','Accuracy','Precision','Recall','F1','Time (s)']]\n",
    "print(\"\\n=== Results (Improved) ===\")\n",
    "print(out.sort_values('Accuracy', ascending=False).to_string(index=False))\n",
    "out.to_csv(RESULTS_CSV, index=False)\n",
    "print(f\"\\nSaved metrics to: {RESULTS_CSV}\")\n",
    "\n",
    "# Confusion matrices\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, np.round(dl_preds['CNN']).astype(int).clip(0,1)),\n",
    "            annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"CNN Confusion Matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "plt.tight_layout(); plt.savefig(\"cm_cnn_improved_300dpi.png\", dpi=300); plt.close()\n",
    "print(\"Saved: cm_cnn_improved_300dpi.png\")\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(ppo_labels, ppo_preds),\n",
    "            annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"PPO Confusion Matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "plt.tight_layout(); plt.savefig(\"cm_ppo_improved_300dpi.png\", dpi=300); plt.close()\n",
    "print(\"Saved: cm_ppo_improved_300dpi.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9adbde4-508c-44f1-97a7-deb9331afcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Split 20% test ===\n",
      "                  Model  Accuracy  Precision   Recall       F1  Time (s)\n",
      "                    CNN  0.564516   0.541432 0.564516 0.488886      0.92\n",
      "PPO (Sequential Hybrid)  0.564516   0.754162 0.564516 0.407383     14.45\n",
      "                Bi-LSTM  0.560484   0.517125 0.560484 0.437896      4.91\n",
      "                   LSTM  0.556452   0.519657 0.556452 0.466501      2.78\n",
      "                XGBoost  0.500000   0.500000 0.500000 0.500000      0.12\n",
      "           Stacked LSTM  0.495968   0.611082 0.495968 0.423582      5.94\n",
      "\n",
      "=== Split 30% test ===\n",
      "                  Model  Accuracy  Precision   Recall       F1  Time (s)\n",
      "                Bi-LSTM  0.583333   0.758356 0.583333 0.438153      4.62\n",
      "PPO (Sequential Hybrid)  0.575269   0.755665 0.575269 0.420162     14.06\n",
      "                   LSTM  0.559140   0.552889 0.559140 0.554721      2.56\n",
      "           Stacked LSTM  0.532258   0.580715 0.532258 0.520958      5.50\n",
      "                    CNN  0.529570   0.467048 0.529570 0.458857      0.89\n",
      "                XGBoost  0.467742   0.535603 0.467742 0.418120      0.11\n",
      "\n",
      "=== Split 40% test ===\n",
      "                  Model  Accuracy  Precision   Recall       F1  Time (s)\n",
      "PPO (Sequential Hybrid)  0.578629   0.757626 0.578629 0.432528     13.69\n",
      "                Bi-LSTM  0.542339   0.494558 0.542339 0.472864      4.08\n",
      "                    CNN  0.534274   0.467233 0.534274 0.451148      0.80\n",
      "                   LSTM  0.522177   0.477823 0.522177 0.471074      2.33\n",
      "           Stacked LSTM  0.522177   0.473605 0.522177 0.466180      5.71\n",
      "                XGBoost  0.479839   0.497136 0.479839 0.480888      0.10\n",
      "\n",
      "Saved: results_20.csv, results_30.csv, results_40.csv, results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SP500 — Multi-Split Comparison (20%, 30%, 40% test)\n",
    "# Models: XGBoost + CNN + LSTM + Bi-LSTM + Stacked LSTM + Sequential PPO\n",
    "# Metrics: Accuracy, Precision, Recall, F1\n",
    "# SMOTE on training only; PPO steps=50k; Reward (+1/-5); Chronological splits\n",
    "# Outputs: results_20.csv, results_30.csv, results_40.csv, results_summary.csv\n",
    "# ============================================================\n",
    "\n",
    "import warnings, time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "FILE_PATH = \"/Users/dhadel/Downloads/Validation_SP500_2017_2022.xlsx\"   # change if needed\n",
    "RANDOM_STATE = 42\n",
    "EPOCHS = 20\n",
    "PPO_STEPS = 50_000\n",
    "POS_REWARD, NEG_REWARD = 1, -5\n",
    "TEST_FRACTIONS = [0.20, 0.30, 0.40]  # 20%, 30%, 40%\n",
    "MIN_MOVE_BAND = 0.0  # set >0.0 (e.g., 0.003) to ignore tiny next-day moves\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def metrics_from_continuous(y_true, y_pred_cont):\n",
    "    yb = np.round(np.nan_to_num(y_pred_cont)).astype(int).clip(0,1)\n",
    "    return {\n",
    "        'Accuracy':  accuracy_score(y_true, yb),\n",
    "        'Precision': precision_score(y_true, yb, average='weighted', zero_division=1),\n",
    "        'Recall':    recall_score(y_true, yb, average='weighted', zero_division=1),\n",
    "        'F1':        f1_score(y_true, yb, average='weighted', zero_division=1)\n",
    "    }\n",
    "\n",
    "def build_features(df):\n",
    "    \"\"\"Causal, lightweight technical features for better signal.\"\"\"\n",
    "    df = df[['Date','Open','High','Low','Close','Volume']].copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    for c in ['Open','High','Low','Close','Volume']:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    df = df.dropna().sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Target: next-day direction (optionally with a neutral band)\n",
    "    next_ret = df['Close'].pct_change().shift(-1)\n",
    "    if MIN_MOVE_BAND > 0.0:\n",
    "        y = np.where(next_ret > MIN_MOVE_BAND, 1, np.where(next_ret < -MIN_MOVE_BAND, 0, np.nan))\n",
    "        df['Direction'] = y\n",
    "        df = df.dropna(subset=['Direction']).copy()\n",
    "        df['Direction'] = df['Direction'].astype(int)\n",
    "    else:\n",
    "        df['Direction'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
    "\n",
    "    # Drop last row (no future label)\n",
    "    df = df.iloc[:-1, :].copy()\n",
    "\n",
    "    # Base features\n",
    "    df['ret'] = df['Close'].pct_change()\n",
    "    for k in [1,2,3,5]:\n",
    "        df[f'lag_ret_{k}'] = df['ret'].shift(k)\n",
    "\n",
    "    for w in [5,10,20]:\n",
    "        df[f'ma_{w}'] = df['Close'].rolling(w, min_periods=w).mean()\n",
    "        df[f'ma_ratio_{w}'] = df['Close'] / (df[f'ma_{w}'] + 1e-12)\n",
    "        df[f'vol_{w}'] = df['ret'].rolling(w, min_periods=w).std()\n",
    "\n",
    "    # RSI(14)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.clip(lower=0).rolling(14, min_periods=14).mean()\n",
    "    loss = (-delta.clip(upper=0)).rolling(14, min_periods=14).mean()\n",
    "    rs = gain / (loss + 1e-12)\n",
    "    df['rsi_14'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # MACD (12,26,9)\n",
    "    ema12 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    macd = ema12 - ema26\n",
    "    signal = macd.ewm(span=9, adjust=False).mean()\n",
    "    df['macd'] = macd\n",
    "    df['macd_signal'] = signal\n",
    "    df['macd_hist'] = macd - signal\n",
    "\n",
    "    # Simple price ratios\n",
    "    df['hl_range'] = (df['High'] - df['Low']) / (df['Close'] + 1e-12)\n",
    "    df['co_ratio'] = df['Close'] / (df['Open'] + 1e-12)\n",
    "\n",
    "    feature_cols = ['Close','High','Low','Volume',\n",
    "                    'ret','lag_ret_1','lag_ret_2','lag_ret_3','lag_ret_5',\n",
    "                    'ma_ratio_5','ma_ratio_10','ma_ratio_20',\n",
    "                    'vol_5','vol_10','vol_20',\n",
    "                    'rsi_14','macd','macd_signal','macd_hist',\n",
    "                    'hl_range','co_ratio']\n",
    "\n",
    "    df = df.dropna(subset=feature_cols + ['Direction']).copy()\n",
    "\n",
    "    X_all = df[feature_cols].replace([np.inf, -np.inf], np.nan).fillna(method='ffill').fillna(method='bfill')\n",
    "    y_all = df['Direction'].astype(int).values\n",
    "    dates = df['Date'].values\n",
    "    return X_all, y_all, dates\n",
    "\n",
    "def make_dl(kind, input_len):\n",
    "    m = Sequential([Input(shape=(input_len,1))])\n",
    "    if kind == 'CNN':\n",
    "        m.add(Conv1D(64, 3, activation='relu')); m.add(Flatten())\n",
    "    elif kind == 'LSTM':\n",
    "        m.add(LSTM(64, activation='relu'))\n",
    "    elif kind == 'Bi-LSTM':\n",
    "        m.add(Bidirectional(LSTM(64, activation='relu')))\n",
    "    elif kind == 'Stacked LSTM':\n",
    "        m.add(LSTM(64, activation='relu', return_sequences=True)); m.add(LSTM(64, activation='relu'))\n",
    "    m.add(Dense(1, activation='linear'))\n",
    "    m.compile(optimizer=Adam(1e-3, clipnorm=1.0), loss='mse')\n",
    "    return m\n",
    "\n",
    "def run_split(X_all, y_all, dates, test_fraction, seed=RANDOM_STATE):\n",
    "    \"\"\"Chronological split → SMOTE on train → scale → train all models → return results DataFrame.\"\"\"\n",
    "    n = len(X_all)\n",
    "    test_start = int(np.floor((1.0 - test_fraction) * n))\n",
    "    X_train, X_test = X_all.iloc[:test_start], X_all.iloc[test_start:]\n",
    "    y_train, y_test = y_all[:test_start], y_all[test_start:]\n",
    "\n",
    "    # SMOTE on training only\n",
    "    sm = SMOTE(random_state=seed)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Scale for DL inputs\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # XGBoost (regressor head)\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=200, max_depth=4, learning_rate=0.05, subsample=0.8,\n",
    "        colsample_bytree=0.9, n_jobs=-1, random_state=seed\n",
    "    )\n",
    "    t0 = time.time(); xgb.fit(X_train, y_train); xgb_time = round(time.time() - t0, 2)\n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "    r = metrics_from_continuous(y_test, xgb_pred); r.update({'Model':'XGBoost','Time (s)': xgb_time}); results.append(r)\n",
    "\n",
    "    # DL models\n",
    "    X_train_dl = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "    X_test_dl  = X_test_scaled.reshape(-1,  X_test_scaled.shape[1], 1)\n",
    "\n",
    "    dl_preds = {}\n",
    "    for name in ['CNN','LSTM','Bi-LSTM','Stacked LSTM']:\n",
    "        mdl = make_dl(name, X_train_dl.shape[1])\n",
    "        t0 = time.time(); mdl.fit(X_train_dl, y_train_res, epochs=EPOCHS, verbose=0); t_dl = round(time.time() - t0, 2)\n",
    "        pred = mdl.predict(X_test_dl, verbose=0).ravel()\n",
    "        dl_preds[name] = pred\n",
    "        r = metrics_from_continuous(y_test, pred); r.update({'Model': name, 'Time (s)': t_dl}); results.append(r)\n",
    "\n",
    "    # PPO sequential hybrid (meta over model outputs)\n",
    "    stack = np.column_stack([\n",
    "        xgb_pred,\n",
    "        dl_preds['CNN'],\n",
    "        dl_preds['LSTM'],\n",
    "        dl_preds['Bi-LSTM'],\n",
    "        dl_preds['Stacked LSTM']\n",
    "    ]).astype(np.float32)\n",
    "\n",
    "    stack = MinMaxScaler().fit_transform(stack).astype(np.float32)\n",
    "    ppo_labels = y_test.astype(int)\n",
    "\n",
    "    class PPOEnv(gym.Env):\n",
    "        def __init__(self, X, y, pos_reward=1, neg_reward=-5):\n",
    "            super().__init__()\n",
    "            self.X, self.y = X, y\n",
    "            self.n = len(y); self.i = 0\n",
    "            self.pos_reward, self.neg_reward = pos_reward, neg_reward\n",
    "            self.observation_space = spaces.Box(low=0, high=1, shape=(X.shape[1],), dtype=np.float32)\n",
    "            self.action_space = spaces.Discrete(2)\n",
    "        def reset(self, seed=None, options=None):\n",
    "            self.i = 0\n",
    "            return self.X[self.i], {}\n",
    "        def step(self, action):\n",
    "            r = self.pos_reward if action == self.y[self.i] else self.neg_reward\n",
    "            self.i += 1\n",
    "            done = self.i >= self.n\n",
    "            obs = self.X[self.i] if not done else np.zeros(self.X.shape[1], dtype=np.float32)\n",
    "            return obs, r, done, False, {}\n",
    "\n",
    "    env = make_vec_env(lambda: PPOEnv(stack, ppo_labels, POS_REWARD, NEG_REWARD), n_envs=1)\n",
    "    ppo = PPO(\"MlpPolicy\", env, verbose=0, seed=seed)\n",
    "    t0 = time.time(); ppo.learn(total_timesteps=PPO_STEPS); ppo_time = round(time.time() - t0, 2)\n",
    "\n",
    "    # Evaluate sequentially\n",
    "    eval_env = PPOEnv(stack, ppo_labels, POS_REWARD, NEG_REWARD)\n",
    "    obs, _ = eval_env.reset(); preds = []; done = False\n",
    "    while not done:\n",
    "        act, _ = ppo.predict(obs, deterministic=True)\n",
    "        preds.append(int(act))\n",
    "        obs, _, done, _, _ = eval_env.step(int(act))\n",
    "\n",
    "    # PPO metrics\n",
    "    ppo_metrics = {\n",
    "        'Accuracy':  accuracy_score(ppo_labels, preds),\n",
    "        'Precision': precision_score(ppo_labels, preds, average='weighted', zero_division=1),\n",
    "        'Recall':    recall_score(ppo_labels, preds, average='weighted', zero_division=1),\n",
    "        'F1':        f1_score(ppo_labels, preds, average='weighted', zero_division=1)\n",
    "    }\n",
    "    ppo_metrics.update({'Model':'PPO (Sequential Hybrid)','Time (s)': ppo_time})\n",
    "    results.append(ppo_metrics)\n",
    "\n",
    "    df_res = pd.DataFrame(results)[['Model','Accuracy','Precision','Recall','F1','Time (s)']]\n",
    "    return df_res\n",
    "\n",
    "# -----------------------\n",
    "# Run once (compute features), then evaluate all splits\n",
    "# -----------------------\n",
    "raw = pd.read_excel(FILE_PATH, engine=\"openpyxl\")\n",
    "X_all, y_all, dates = build_features(raw)\n",
    "\n",
    "summary_rows = []\n",
    "for frac in TEST_FRACTIONS:\n",
    "    df_split = run_split(X_all, y_all, dates, test_fraction=frac)\n",
    "    fname = f\"results_{int(frac*100)}.csv\"\n",
    "    df_split.to_csv(fname, index=False)\n",
    "    print(f\"\\n=== Split {int(frac*100)}% test ===\")\n",
    "    print(df_split.sort_values('Accuracy', ascending=False).to_string(index=False))\n",
    "    # collect for summary\n",
    "    tmp = df_split.copy()\n",
    "    tmp.insert(0, 'Split', f\"{int(frac*100)}%\")\n",
    "    summary_rows.append(tmp)\n",
    "\n",
    "summary = pd.concat(summary_rows, ignore_index=True)\n",
    "summary.to_csv(\"results_summary.csv\", index=False)\n",
    "print(\"\\nSaved: results_20.csv, results_30.csv, results_40.csv, results_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dca19d-3805-4cb2-a219-32ec6b34a331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda3)",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
