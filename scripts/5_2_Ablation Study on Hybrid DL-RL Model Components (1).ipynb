{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d476b-7dd0-40ae-8803-798f7bdd31eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [21:12:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Standalone & Sequential PPO (Pairs / All DL / XGB+All DL) ===\n",
      "                Model    Variant  Accuracy  Precision   Recall  F1-Score      MCC  Cohen's Kappa      FNR  Time (s)\n",
      "     PPO-Seq: XGB+CNN    PPO-Seq  0.994739   0.994733 0.994739  0.994735 0.984050       0.984046 0.014706     23.36\n",
      "  PPO-Seq: XGB+BiLSTM    PPO-Seq  0.994301   0.994297 0.994301  0.994299 0.982731       0.982730 0.014706     23.70\n",
      "PPO-Seq: XGB + All DL    PPO-Seq  0.994301   0.994297 0.994301  0.994299 0.982731       0.982730 0.014706     27.38\n",
      "    PPO-Seq: XGB+LSTM    PPO-Seq  0.993862   0.993862 0.993862  0.993862 0.981416       0.981416 0.014706     23.73\n",
      " PPO-Seq: XGB+Stacked    PPO-Seq  0.993424   0.993419 0.993424  0.993421 0.980074       0.980073 0.016807     29.77\n",
      "      PPO-Seq: All DL    PPO-Seq  0.986409   0.986360 0.986409  0.986362 0.958631       0.958561 0.042017     28.17\n",
      "              XGBoost Standalone  0.992986   0.992974 0.992986  0.992969 0.978693       0.978662 0.023109      2.25\n",
      "              Bi-LSTM Standalone  0.984217   0.984164 0.984217  0.984180 0.952020       0.951990 0.044118     24.26\n",
      "                  CNN Standalone  0.983779   0.983730 0.983779  0.983747 0.950716       0.950694 0.044118      1.33\n",
      "         Stacked LSTM Standalone  0.983341   0.983290 0.983341  0.983221 0.949124       0.948846 0.058824     23.67\n",
      "                 LSTM Standalone  0.978518   0.978764 0.978518  0.978608 0.935603       0.935505 0.039916     12.21\n",
      "\n",
      "Saved: standalone_and_seqppo_hybrid_results.csv\n"
     ]
    }
   ],
   "source": [
    "import warnings, os, time, random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "random.seed(42); np.random.seed(42)\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, matthews_corrcoef, cohen_kappa_score)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "file_path = os.path.join(\"Data\", \"Hybrid_Augmented_TSAFE_Features.xlsx\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "if 'Plant_Destination' not in df.columns and {'Plant Code','Destination Port'}.issubset(df.columns):\n",
    "    df['Plant_Destination'] = df['Plant Code'].astype(str) + ' | ' + df['Destination Port'].astype(str)\n",
    "\n",
    "cat_features = [c for c in ['Origin Port','Carrier','Plant Code','Destination Port','Plant_Destination'] if c in df.columns]\n",
    "num_features = [c for c in [\n",
    "    'Unit quantity','Weight','TPT',\n",
    "    'TPT_per_Unit','LeadTime_Deviation','Weight_per_Unit','log_UnitQty',\n",
    "    'carrier_origin_risk','route_cum_late_rate','route_bb_mean','carrier_bb_mean',\n",
    "    'route_orders_last7d','route_roll10_Weight_q90',\n",
    "    'congestion_trend','Weight_vsCarrierMean','seq_pos_norm'\n",
    "] if c in df.columns]\n",
    "\n",
    "\n",
    "if 'Ship Late Day count' not in df.columns:\n",
    "    raise ValueError(\"Missing target column 'Ship Late Day count'.\")\n",
    "y = (df['Ship Late Day count'] > 0).astype(int)\n",
    "\n",
    "has_date = 'Order Date' in df.columns\n",
    "if has_date:\n",
    "    df['Order Date'] = pd.to_datetime(df['Order Date'], errors='coerce')\n",
    "\n",
    "\n",
    "X = pd.get_dummies(df[cat_features + num_features], drop_first=False)\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median(numeric_only=True))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "def compute_all_metrics(y_true, y_score_or_pred):\n",
    "    arr = np.asarray(y_score_or_pred).reshape(-1)\n",
    "    if set(np.unique(arr)) <= {0,1}:\n",
    "        y_pred = arr.astype(int)\n",
    "    else:\n",
    "        y_pred = (arr >= 0.5).astype(int)\n",
    "\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "    rec  = recall_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "    f1   = f1_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "    mcc  = matthews_corrcoef(y_true, y_pred)\n",
    "    kap  = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1-Score': f1,\n",
    "        'MCC': mcc, \"Cohen's Kappa\": kap, 'FNR': fnr\n",
    "    }\n",
    "\n",
    "def as_row(name, m, t, kind):\n",
    "    r = m.copy(); r.update({'Model': name, 'Variant': kind, 'Time (s)': round(float(t),2)})\n",
    "    return r\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "\n",
    "xgb = GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False),\n",
    "    param_grid={'n_estimators':[200], 'max_depth':[4,6], 'learning_rate':[0.1,0.05], 'subsample':[0.8]},\n",
    "    scoring='roc_auc', cv=3, n_jobs=-1\n",
    ")\n",
    "t0 = time.time()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_time = time.time() - t0\n",
    "xgb_proba = xgb.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "all_rows.append(as_row('XGBoost', compute_all_metrics(y_test, xgb_proba), xgb_time, 'Standalone'))\n",
    "\n",
    "\n",
    "def create_model(model_type, input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim, 1)))\n",
    "    if model_type == 'CNN':\n",
    "        model.add(Conv1D(64, 2, activation='relu')); model.add(Flatten())\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(LSTM(64, activation='tanh'))\n",
    "    elif model_type == 'Bi-LSTM':\n",
    "        model.add(Bidirectional(LSTM(64, activation='tanh')))\n",
    "    elif model_type == 'Stacked LSTM':\n",
    "        model.add(LSTM(64, activation='tanh', return_sequences=True))\n",
    "        model.add(LSTM(32, activation='tanh'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3, clipnorm=1.0), loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "X_train_dl = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "X_test_dl  = X_test_scaled.reshape(-1,  X_test_scaled.shape[1],  1)\n",
    "\n",
    "dl_models = ['CNN', 'LSTM', 'Bi-LSTM', 'Stacked LSTM']\n",
    "dl_outputs, dl_times = {}, {}\n",
    "\n",
    "for m in dl_models:\n",
    "    mdl = create_model(m, X_train_dl.shape[1])\n",
    "    t0 = time.time()\n",
    "    mdl.fit(X_train_dl, y_train_res, epochs=10, batch_size=256, verbose=0)\n",
    "    dl_times[m] = time.time() - t0\n",
    "    proba = mdl.predict(X_test_dl, verbose=0).reshape(-1)\n",
    "    dl_outputs[m] = proba\n",
    "    all_rows.append(as_row(m, compute_all_metrics(y_test, proba), dl_times[m], 'Standalone'))\n",
    "\n",
    "\n",
    "test_idx = X_test.index\n",
    "cols_for_frame = [c for c in ['Order Date','Origin Port','Destination Port','Carrier'] if c in df.columns]\n",
    "test_frame = df.loc[test_idx, cols_for_frame].copy()\n",
    "if has_date:\n",
    "    test_frame['Order Date'] = pd.to_datetime(test_frame['Order Date'])\n",
    "else:\n",
    "    test_frame['Order Date'] = np.arange(len(test_idx))\n",
    "\n",
    "test_frame['y']   = y_test.values.astype(int)\n",
    "test_frame['xgb'] = xgb_proba\n",
    "for m in dl_models:\n",
    "    test_frame[m] = dl_outputs[m]\n",
    "\n",
    "\n",
    "if set(['Origin Port','Destination Port','Carrier']).issubset(test_frame.columns):\n",
    "    test_frame['route_key'] = (\n",
    "        test_frame['Origin Port'].astype(str) + ' | ' +\n",
    "        test_frame['Destination Port'].astype(str) + ' | ' +\n",
    "        test_frame['Carrier'].astype(str)\n",
    "    )\n",
    "else:\n",
    "    test_frame['route_key'] = 'ALL'\n",
    "\n",
    "test_frame = test_frame.sort_values('Order Date').reset_index(drop=True)\n",
    "labels_sorted = test_frame['y'].values.astype(int)\n",
    "route_sorted  = test_frame['route_key'].values\n",
    "\n",
    "episodes = []\n",
    "start = 0\n",
    "for i in range(1, len(test_frame)+1):\n",
    "    if i == len(test_frame) or route_sorted[i] != route_sorted[i-1]:\n",
    "        episodes.append(slice(start, i))\n",
    "        start = i\n",
    "\n",
    "class SequentialPPOEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Sequential PPO with temporal extras and cost-sensitive rewards.\n",
    "    Observation = [base_inputs(D), time_sin, time_cos, last_K_actions(K), cum_FP, cum_FN]\n",
    "    Action = {0,1}\n",
    "    \"\"\"\n",
    "    metadata = {\"render_modes\": []}\n",
    "\n",
    "    def __init__(self, base_inputs, labels, episodes,\n",
    "                 K=5, reward_correct_pos=2.0, reward_correct_neg=1.0,\n",
    "                 penalty_FN=-5.0, penalty_FP=-2.0,\n",
    "                 step_penalty=-0.01, fn_improve_bonus=0.2):\n",
    "        super().__init__()\n",
    "        self.X = base_inputs.astype(np.float32)           # shape (N, D)\n",
    "        self.y = labels.astype(int)\n",
    "        self.episodes = episodes\n",
    "        self.K = int(K)\n",
    "\n",
    "        # Rewards\n",
    "        self.reward_correct_pos = float(reward_correct_pos)\n",
    "        self.reward_correct_neg = float(reward_correct_neg)\n",
    "        self.penalty_FN = float(penalty_FN)\n",
    "        self.penalty_FP = float(penalty_FP)\n",
    "        self.step_penalty = float(step_penalty)\n",
    "        self.fn_improve_bonus = float(fn_improve_bonus)\n",
    "\n",
    "        D = self.X.shape[1]\n",
    "        self.obs_dim = D + 2 + self.K + 2               # D + time(2) + lastK + cumFP/FN(2)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.obs_dim,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "        self._ep_idx = -1\n",
    "        self._indices = None\n",
    "        self._t = None\n",
    "        self._last_actions = None\n",
    "        self._cum_fp = None\n",
    "        self._cum_fn = None\n",
    "        self._prev_fn_rate = 0.0\n",
    "\n",
    "    def _time_features(self, t, T):\n",
    "        pos = (t / max(T - 1, 1))\n",
    "        return np.array([np.sin(2*np.pi*pos), np.cos(2*np.pi*pos)], dtype=np.float32)\n",
    "\n",
    "    def _obs(self):\n",
    "        T = len(self._indices)\n",
    "        cur_idx = self._indices[self._t]\n",
    "        base = self.X[cur_idx]  # (D,)\n",
    "        parts = [base, self._time_features(self._t, T), self._last_actions,\n",
    "                 np.array([self._cum_fp, self._cum_fn], dtype=np.float32)]\n",
    "        return np.concatenate(parts, axis=0).astype(np.float32)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self._ep_idx = (self._ep_idx + 1) % len(self.episodes)\n",
    "        sl = self.episodes[self._ep_idx]\n",
    "        self._indices = np.arange(sl.start, sl.stop, dtype=int)\n",
    "        self._t = 0\n",
    "        self._last_actions = np.zeros(self.K, dtype=np.float32)\n",
    "        self._cum_fp = 0.0; self._cum_fn = 0.0; self._prev_fn_rate = 0.0\n",
    "        return self._obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        cur_i = self._indices[self._t]\n",
    "        y = self.y[cur_i]\n",
    "\n",
    "       \n",
    "        if action == y:\n",
    "            reward = self.reward_correct_pos if y == 1 else self.reward_correct_neg\n",
    "        else:\n",
    "            if y == 1 and action == 0:\n",
    "                reward = self.penalty_FN; self._cum_fn += 1.0\n",
    "            else:\n",
    "                reward = self.penalty_FP; self._cum_fp += 1.0\n",
    "        reward += self.step_penalty\n",
    "\n",
    "    \n",
    "        steps_so_far = float(self._t + 1)\n",
    "        fn_rate = self._cum_fn / steps_so_far\n",
    "        if fn_rate < self._prev_fn_rate:\n",
    "            reward += self.fn_improve_bonus\n",
    "        self._prev_fn_rate = fn_rate\n",
    "\n",
    "      \n",
    "        self._last_actions = np.roll(self._last_actions, -1)\n",
    "        self._last_actions[-1] = float(action)\n",
    "\n",
    "        \n",
    "        self._t += 1\n",
    "        terminated = self._t >= len(self._indices)\n",
    "        obs = np.zeros(self.obs_dim, dtype=np.float32) if terminated else self._obs()\n",
    "        return obs, float(reward), terminated, False, {}\n",
    "\n",
    "\n",
    "def train_eval_seqppo(input_mat, name, timesteps=80_000, K=5,\n",
    "                      reward_correct_pos=2.0, reward_correct_neg=1.0,\n",
    "                      penalty_FN=-5.0, penalty_FP=-2.0, step_penalty=-0.01, fn_improve_bonus=0.2):\n",
    "    X_in = MinMaxScaler().fit_transform(input_mat).astype(np.float32)\n",
    "\n",
    "    def mk_env():\n",
    "        return SequentialPPOEnv(\n",
    "            base_inputs=X_in, labels=labels_sorted, episodes=episodes,\n",
    "            K=K, reward_correct_pos=reward_correct_pos, reward_correct_neg=reward_correct_neg,\n",
    "            penalty_FN=penalty_FN, penalty_FP=penalty_FP,\n",
    "            step_penalty=step_penalty, fn_improve_bonus=fn_improve_bonus\n",
    "        )\n",
    "\n",
    "    env = make_vec_env(mk_env, n_envs=1)\n",
    "    model = PPO(\"MlpPolicy\", env, verbose=0, seed=42)\n",
    "    t0 = time.time()\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    runtime = time.time() - t0\n",
    "\n",
    "    eval_env = mk_env()\n",
    "    obs, _ = eval_env.reset()\n",
    "    preds, visited = [], 0\n",
    "    while True:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        preds.append(int(action))\n",
    "        obs, _, terminated, truncated, _ = eval_env.step(action)\n",
    "        if terminated:\n",
    "            visited += 1\n",
    "            if visited >= len(episodes):\n",
    "                break\n",
    "            obs, _ = eval_env.reset()\n",
    "\n",
    "    preds = np.array(preds[:len(labels_sorted)])\n",
    "    all_rows.append(as_row(name, compute_all_metrics(labels_sorted, preds), runtime, 'PPO-Seq'))\n",
    "    return runtime\n",
    "\n",
    "pair_specs = [\n",
    "    ('PPO-Seq: XGB+CNN',    test_frame[['xgb','CNN']].values),\n",
    "    ('PPO-Seq: XGB+LSTM',   test_frame[['xgb','LSTM']].values),\n",
    "    ('PPO-Seq: XGB+BiLSTM', test_frame[['xgb','Bi-LSTM']].values),\n",
    "    ('PPO-Seq: XGB+Stacked',test_frame[['xgb','Stacked LSTM']].values),\n",
    "]\n",
    "for name, mat in pair_specs:\n",
    "    train_eval_seqppo(mat, name)\n",
    "\n",
    "\n",
    "all_dl_cols = ['CNN','LSTM','Bi-LSTM','Stacked LSTM']\n",
    "mat_all_dl = test_frame[all_dl_cols].values\n",
    "train_eval_seqppo(mat_all_dl, 'PPO-Seq: All DL')\n",
    "\n",
    "mat_xgb_all = test_frame[['xgb'] + all_dl_cols].values\n",
    "train_eval_seqppo(mat_xgb_all, 'PPO-Seq: XGB + All DL')\n",
    "\n",
    "results_df = pd.DataFrame(all_rows)\n",
    "order = ['Model','Variant','Accuracy','Precision','Recall','F1-Score','MCC',\"Cohen's Kappa\",'FNR','Time (s)']\n",
    "results_df = results_df[order].sort_values(\n",
    "    by=['Variant','F1-Score','MCC','Recall'], ascending=[True, False, False, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Standalone & Sequential PPO (Pairs / All DL / XGB+All DL) ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "out_csv = 'standalone_and_seqppo_hybrid_results.csv'\n",
    "results_df.to_csv(out_csv, index=False)\n",
    "print(f\"\\nSaved: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c155910-85ae-40e5-a6bc-f75b328b59e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda3)",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
