{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad49f80-77ab-42a7-8a6e-686c16b06b6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T03:05:02.010162Z",
     "iopub.status.busy": "2025-08-25T03:05:02.010162Z",
     "iopub.status.idle": "2025-08-25T03:33:17.914715Z",
     "shell.execute_reply": "2025-08-25T03:33:17.914715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved to: C:\\Users\\ramak\\SupplyChain-DL-RL\\results\\BASELINE_CODE\n",
      "   Accuracy  Precision    Recall  F1-Score             Model  Time (s)\n",
      "5  0.994739   0.994774  0.994739  0.994714      PPO (Static)    374.49\n",
      "6  0.994301   0.994297  0.994301  0.994299  PPO (Sequential)    624.88\n",
      "4  0.993862   0.993861  0.993862  0.993843           XGBoost      0.00\n",
      "0  0.983779   0.983767  0.983779  0.983773               CNN     14.88\n",
      "2  0.983341   0.983298  0.983341  0.983315           Bi-LSTM    171.03\n",
      "1  0.978957   0.978878  0.978957  0.978907              LSTM    118.17\n",
      "3  0.969312   0.971032  0.969312  0.969758      Stacked LSTM    270.73\n"
     ]
    }
   ],
   "source": [
    "# === BASELINE CODE (fixed + results routing) ===\n",
    "\n",
    "import os, time, random\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ---------------- Seeds ----------------\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# ---------------- Data path (portable) ----------------\n",
    "candidates = [\n",
    "    Path(\"Data/Hybrid_Augmented_TSAFE_Features.xlsx\"),\n",
    "    Path(\"../Data/Hybrid_Augmented_TSAFE_Features.xlsx\"),\n",
    "    Path(\"../data/Hybrid_Augmented_TSAFE_Features.xlsx\"),\n",
    "]\n",
    "for p in candidates:\n",
    "    if p.exists():\n",
    "        file_path = str(p)\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Could not find Excel. Tried: {candidates}. CWD={Path.cwd()}\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# ---------------- Results folder (repo-root/results/<file-name>) ----------------\n",
    "ROOT = Path.cwd()\n",
    "if ROOT.name.lower() == \"scripts\":\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "SECTION = os.getenv(\"RESULTS_SECTION\")\n",
    "if not SECTION:\n",
    "    try:\n",
    "        SECTION = Path(__file__).stem\n",
    "    except NameError:\n",
    "        SECTION = \"BASELINE_CODE\"\n",
    "\n",
    "OUTDIR = ROOT / \"results\" / SECTION\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- Feature prep ----------------\n",
    "if 'Plant_Destination' not in df.columns:\n",
    "    if {'Plant Code', 'Destination Port'}.issubset(df.columns):\n",
    "        df['Plant_Destination'] = df['Plant Code'].astype(str) + ' | ' + df['Destination Port'].astype(str)\n",
    "    else:\n",
    "        raise ValueError(\"Cannot create 'Plant_Destination' because 'Plant Code' or 'Destination Port' is missing.\")\n",
    "\n",
    "cat_features = [\n",
    "    'Origin Port','Carrier','Plant Code','Destination Port','Plant_Destination'\n",
    "]\n",
    "num_features = [\n",
    "    'Unit quantity','Weight','TPT',\n",
    "    'TPT_per_Unit','LeadTime_Deviation','Weight_per_Unit',\n",
    "    'log_UnitQty','carrier_origin_risk','route_cum_late_rate',\n",
    "    'route_bb_mean','carrier_bb_mean','route_orders_last7d',\n",
    "    'route_roll10_Weight_q90','congestion_trend','Weight_vsCarrierMean','seq_pos_norm'\n",
    "]\n",
    "\n",
    "requested_cols = cat_features + num_features\n",
    "missing = [c for c in requested_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(f\"[WARN] Missing columns will be skipped: {missing}\")\n",
    "    cat_features = [c for c in cat_features if c in df.columns]\n",
    "    num_features = [c for c in num_features if c in df.columns]\n",
    "\n",
    "X = pd.get_dummies(df[cat_features + num_features], drop_first=False)\n",
    "y = (df['Ship Late Day count'] > 0).astype(int)\n",
    "\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median(numeric_only=True))\n",
    "\n",
    "# ---------------- Train/test split + SMOTE + scaling ----------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# ---------------- Metrics helper ----------------\n",
    "def calculate_metrics(y_true, y_score_or_pred):\n",
    "    arr = np.asarray(y_score_or_pred).reshape(-1)\n",
    "    if set(np.unique(arr)) <= {0, 1}:\n",
    "        y_pred = arr.astype(int)\n",
    "    else:\n",
    "        y_pred = (arr >= 0.5).astype(int)\n",
    "    return {\n",
    "        'Accuracy':  float(accuracy_score(y_true, y_pred)),\n",
    "        'Precision': float(precision_score(y_true, y_pred, average='weighted', zero_division=1)),\n",
    "        'Recall':    float(recall_score(y_true, y_pred, average='weighted', zero_division=1)),\n",
    "        'F1-Score':  float(f1_score(y_true, y_pred, average='weighted', zero_division=1))\n",
    "    }\n",
    "\n",
    "# ---------------- XGBoost (with small grid) ----------------\n",
    "xgb = GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    param_grid={'n_estimators':[100], 'max_depth':[3,5], 'learning_rate':[0.1,0.05], 'subsample':[0.8]},\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_proba = xgb.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "xgb_metrics = calculate_metrics(y_test, xgb_proba)\n",
    "\n",
    "# ---------------- Simple DL models ----------------\n",
    "def create_model(model_type, input_dim):\n",
    "    m = Sequential()\n",
    "    m.add(Input(shape=(input_dim, 1)))\n",
    "    if model_type == 'CNN':\n",
    "        m.add(Conv1D(64, 2, activation='relu')); m.add(Flatten())\n",
    "    elif model_type == 'LSTM':\n",
    "        m.add(LSTM(64, activation='tanh'))\n",
    "    elif model_type == 'Bi-LSTM':\n",
    "        m.add(Bidirectional(LSTM(64, activation='tanh')))\n",
    "    elif model_type == 'Stacked LSTM':\n",
    "        m.add(LSTM(64, activation='tanh', return_sequences=True)); m.add(LSTM(32, activation='tanh'))\n",
    "    m.add(Dense(1, activation='sigmoid'))\n",
    "    m.compile(optimizer=Adam(learning_rate=1e-3, clipnorm=1.0), loss='binary_crossentropy')\n",
    "    return m\n",
    "\n",
    "X_train_dl = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "X_test_dl  = X_test_scaled.reshape(-1,  X_test_scaled.shape[1],  1)\n",
    "\n",
    "dl_models = ['CNN', 'LSTM', 'Bi-LSTM', 'Stacked LSTM']\n",
    "results = []\n",
    "dl_outputs = {}\n",
    "\n",
    "for mname in dl_models:\n",
    "    mdl = create_model(mname, X_train_dl.shape[1])\n",
    "    t0 = time.time()\n",
    "    mdl.fit(X_train_dl, y_train_res, epochs=10, batch_size=256, verbose=0)\n",
    "    duration = round(time.time() - t0, 2)\n",
    "    proba = mdl.predict(X_test_dl, verbose=0).reshape(-1)\n",
    "    dl_outputs[mname] = proba\n",
    "    met = calculate_metrics(y_test, proba)\n",
    "    met.update({'Model': mname, 'Time (s)': duration})\n",
    "    results.append(met)\n",
    "\n",
    "xgb_met = xgb_metrics.copy()\n",
    "xgb_met.update({'Model': 'XGBoost', 'Time (s)': 0.0})\n",
    "results.append(xgb_met)\n",
    "\n",
    "# ---------------- PPO (Static) ----------------\n",
    "ppo_input_static = np.vstack([\n",
    "    xgb_proba,\n",
    "    dl_outputs['CNN'],\n",
    "    dl_outputs['LSTM'],\n",
    "    dl_outputs['Bi-LSTM'],\n",
    "    dl_outputs['Stacked LSTM']\n",
    "]).T.astype(np.float32)\n",
    "\n",
    "ppo_input_static = MinMaxScaler().fit_transform(ppo_input_static).astype(np.float32)\n",
    "ppo_labels_static = y_test.values.astype(int)\n",
    "\n",
    "class PPOHybridEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": []}\n",
    "    def __init__(self, inputs, labels, pos_reward=1.0, neg_reward=-5.0):\n",
    "        super().__init__()\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        self.n = len(labels)\n",
    "        self.pos_reward = pos_reward\n",
    "        self.neg_reward = neg_reward\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(inputs.shape[1],), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.idx = 0\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.idx = 0\n",
    "        return self.inputs[self.idx], {}\n",
    "    def step(self, action):\n",
    "        reward = self.pos_reward if action == self.labels[self.idx] else self.neg_reward\n",
    "        self.idx += 1\n",
    "        terminated = self.idx >= self.n\n",
    "        obs = np.zeros(self.inputs.shape[1], dtype=np.float32) if terminated else self.inputs[self.idx]\n",
    "        return obs, float(reward), terminated, False, {}\n",
    "\n",
    "env_static = make_vec_env(lambda: PPOHybridEnv(ppo_input_static, ppo_labels_static), n_envs=1)\n",
    "ppo_model_static = PPO(\"MlpPolicy\", env_static, verbose=0, seed=42)\n",
    "t0 = time.time()\n",
    "ppo_model_static.learn(total_timesteps=50_000)\n",
    "ppo_static_time = round(time.time() - t0, 2)\n",
    "\n",
    "env_eval_static = PPOHybridEnv(ppo_input_static, ppo_labels_static)\n",
    "obs, _ = env_eval_static.reset()\n",
    "ppo_preds_static = []\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = ppo_model_static.predict(obs, deterministic=True)\n",
    "    ppo_preds_static.append(int(action))\n",
    "    obs, _, done, _, _ = env_eval_static.step(action)\n",
    "\n",
    "ppo_metrics_static = calculate_metrics(ppo_labels_static, np.array(ppo_preds_static))\n",
    "ppo_metrics_static.update({'Model': 'PPO (Static)', 'Time (s)': ppo_static_time})\n",
    "results.append(ppo_metrics_static)\n",
    "\n",
    "# ---------------- Build temporal order + sequential PPO ----------------\n",
    "test_idx = X_test.index\n",
    "need_cols = [c for c in ['Order Date','Origin Port','Destination Port','Carrier'] if c in df.columns]\n",
    "test_frame = df.loc[test_idx, need_cols].copy()\n",
    "if 'Order Date' in test_frame.columns:\n",
    "    test_frame['Order Date'] = pd.to_datetime(test_frame['Order Date'])\n",
    "\n",
    "test_frame['y'] = y_test.values.astype(int)\n",
    "test_frame['xgb'] = xgb_proba\n",
    "for m in dl_models:\n",
    "    test_frame[m] = dl_outputs[m]\n",
    "\n",
    "if all(c in test_frame.columns for c in ['Origin Port','Destination Port','Carrier']):\n",
    "    test_frame['route_key'] = (\n",
    "        test_frame['Origin Port'].astype(str) + ' | ' +\n",
    "        test_frame['Destination Port'].astype(str) + ' | ' +\n",
    "        test_frame['Carrier'].astype(str)\n",
    "    )\n",
    "else:\n",
    "    test_frame['route_key'] = \"ALL\"\n",
    "\n",
    "if 'Order Date' in test_frame.columns:\n",
    "    test_frame = test_frame.sort_values('Order Date').reset_index(drop=True)\n",
    "else:\n",
    "    test_frame = test_frame.reset_index(drop=True)\n",
    "\n",
    "base_inputs = test_frame[['xgb','CNN','LSTM','Bi-LSTM','Stacked LSTM']].values.astype(np.float32)\n",
    "base_inputs = MinMaxScaler().fit_transform(base_inputs).astype(np.float32)\n",
    "labels_sorted = test_frame['y'].values.astype(int)\n",
    "route_sorted  = test_frame['route_key'].values\n",
    "\n",
    "episodes = []\n",
    "start = 0\n",
    "for i in range(1, len(test_frame) + 1):\n",
    "    if i == len(test_frame) or route_sorted[i] != route_sorted[i-1]:\n",
    "        episodes.append(slice(start, i))\n",
    "        start = i\n",
    "\n",
    "class SequentialPPOEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": []}\n",
    "    def __init__(self, base_inputs, labels, episodes, K=5):\n",
    "        super().__init__()\n",
    "        self.base_inputs = base_inputs\n",
    "        self.labels = labels.astype(int)\n",
    "        self.episodes = episodes\n",
    "        self.K = K\n",
    "        self.obs_dim = 5 + 2 + K + 2\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.obs_dim,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self._ep_idx = -1\n",
    "        self._indices = None\n",
    "        self._t = None\n",
    "        self._last_actions = None\n",
    "        self._cum_fp = None\n",
    "        self._cum_fn = None\n",
    "        self._prev_fn_rate = 0.0\n",
    "    def _time_features(self, t, T):\n",
    "        pos = (t / max(T - 1, 1))\n",
    "        return np.array([np.sin(2*np.pi*pos), np.cos(2*np.pi*pos)], dtype=np.float32)\n",
    "    def _obs(self):\n",
    "        T = len(self._indices)\n",
    "        cur_idx = self._indices[self._t]\n",
    "        x = self.base_inputs[cur_idx]\n",
    "        time_feat = self._time_features(self._t, T)\n",
    "        lastK = self._last_actions.copy()\n",
    "        obs = np.concatenate([x, time_feat, lastK, np.array([self._cum_fp, self._cum_fn], dtype=np.float32)], axis=0)\n",
    "        return obs.astype(np.float32)\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self._ep_idx = (self._ep_idx + 1) % len(self.episodes)\n",
    "        sl = self.episodes[self._ep_idx]\n",
    "        self._indices = np.arange(sl.start, sl.stop, dtype=int)\n",
    "        self._t = 0\n",
    "        self._last_actions = np.zeros(self.K, dtype=np.float32)\n",
    "        self._cum_fp = 0.0\n",
    "        self._cum_fn = 0.0\n",
    "        self._prev_fn_rate = 0.0\n",
    "        return self._obs(), {}\n",
    "    def step(self, action):\n",
    "        cur_i = self._indices[self._t]\n",
    "        y = self.labels[cur_i]\n",
    "        if action == y:\n",
    "            reward = 2.0 if y == 1 else 1.0\n",
    "        else:\n",
    "            if y == 1 and action == 0:\n",
    "                reward = -5.0\n",
    "                self._cum_fn += 1.0\n",
    "            else:\n",
    "                reward = -2.0\n",
    "                self._cum_fp += 1.0\n",
    "        reward -= 0.01\n",
    "        steps_so_far = float(self._t + 1)\n",
    "        fn_rate = self._cum_fn / steps_so_far\n",
    "        if fn_rate < self._prev_fn_rate:\n",
    "            reward += 0.2\n",
    "        self._prev_fn_rate = fn_rate\n",
    "        self._last_actions = np.roll(self._last_actions, -1)\n",
    "        self._last_actions[-1] = float(action)\n",
    "        self._t += 1\n",
    "        terminated = self._t >= len(self._indices)\n",
    "        truncated = False\n",
    "        obs = np.zeros(self.obs_dim, dtype=np.float32) if terminated else self._obs()\n",
    "        return obs, float(reward), terminated, truncated, {}\n",
    "\n",
    "env_seq = make_vec_env(lambda: SequentialPPOEnv(base_inputs, labels_sorted, episodes, K=5), n_envs=1)\n",
    "ppo_model_seq = PPO(\"MlpPolicy\", env_seq, verbose=0, seed=42)\n",
    "t0 = time.time()\n",
    "ppo_model_seq.learn(total_timesteps=80_000)\n",
    "ppo_seq_time = round(time.time() - t0, 2)\n",
    "\n",
    "eval_env = SequentialPPOEnv(base_inputs, labels_sorted, episodes, K=5)\n",
    "obs, _ = eval_env.reset()\n",
    "seq_preds = []\n",
    "visited_episodes = 0\n",
    "while True:\n",
    "    action, _ = ppo_model_seq.predict(obs, deterministic=True)\n",
    "    seq_preds.append(int(action))\n",
    "    obs, _, terminated, truncated, _ = eval_env.step(action)\n",
    "    if terminated:\n",
    "        visited_episodes += 1\n",
    "        if visited_episodes >= len(episodes):\n",
    "            break\n",
    "        obs, _ = eval_env.reset()\n",
    "\n",
    "seq_preds = np.array(seq_preds[:len(labels_sorted)])\n",
    "seq_metrics = calculate_metrics(labels_sorted, seq_preds)\n",
    "seq_metrics.update({'Model': 'PPO (Sequential)', 'Time (s)': ppo_seq_time})\n",
    "results.append(seq_metrics)\n",
    "\n",
    "# ---------------- Save results + figures ----------------\n",
    "results_df = pd.DataFrame(results).sort_values('F1-Score', ascending=False)\n",
    "results_df.to_csv(OUTDIR / 'model_comparison_static_vs_sequential_PPO.csv', index=False)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, (dl_outputs['CNN'] >= 0.5).astype(int)), annot=True, fmt='d')\n",
    "plt.title(\"DL (CNN) Confusion Matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "plt.tight_layout(); plt.savefig(OUTDIR / \"cm_dl_cnn.png\", dpi=300); plt.close()\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(ppo_labels_static, np.array(ppo_preds_static)), annot=True, fmt='d')\n",
    "plt.title(\"PPO (Static) Confusion Matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "plt.tight_layout(); plt.savefig(OUTDIR / \"cm_ppo_static.png\", dpi=300); plt.close()\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(labels_sorted, seq_preds), annot=True, fmt='d')\n",
    "plt.title(\"PPO (Sequential) Confusion Matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "plt.tight_layout(); plt.savefig(OUTDIR / \"cm_ppo_sequential.png\", dpi=300); plt.close()\n",
    "\n",
    "print(\"\\nSaved to:\", OUTDIR.resolve())\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda3)",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
